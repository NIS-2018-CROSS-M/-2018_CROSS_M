{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### set up telegram notifications\n",
    "\n",
    "  не очень понятно, нужно ли это.\n",
    "\n",
    "  если нужно -- напишите @oserikov в телеграме, я расскажу, что сделать,\n",
    "  чтобы присылались сообщения с качеством модели когда она отработает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_notifications_enabled=False\n",
    "EXP_DESCRIPTION = \"BASELINE\"\n",
    "\n",
    "if telegram_notifications_enabled:\n",
    "    bot_token = input(\"введите telegram bot token: \")\n",
    "    chat_id = \"292749902\" # for @oserikov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### install prereqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system(f\"git clone https://github.com/NIS-2018-CROSS-M/colab-tools.git\")\n",
    "get_ipython().magic(f\"cd colab-tools\")\n",
    "get_ipython().system(f\"bash colab-install-opennmt.sh\")\n",
    "get_ipython().system(f\"bash colab-install-cuda92-pytorch41.sh\")\n",
    "get_ipython().system(f\"bash colab-install-torchtext.sh\")\n",
    "get_ipython().magic(f\"cd ..\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies used in calma project\n",
    "get_ipython().system('/usr/bin/python3 -m pip install configargparse')\n",
    "get_ipython().system('git clone https://github.com/NIS-2018-CROSS-M/calma_tools.git')\n",
    "\n",
    "# receive the calma\n",
    "get_ipython().system('git clone https://github.com/ftyers/calma.git')\n",
    "get_ipython().magic('cd calma')\n",
    "get_ipython().system('git checkout -b latest-known-version d4ce3758d06538933855f734a44630efc8e2b6b2')\n",
    "get_ipython().system('rm sharedtaskdata/onmt-data/*')\n",
    "get_ipython().system('rm sharedtaskdata/results/*')\n",
    "get_ipython().magic('cd ..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(get_ipython().getoutput(\"readlink -e calma_tools\")[0])\n",
    "from calma_tools.ml_util import MLUtil\n",
    "import urllib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic('cd calma/sharedtaskdata')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs=['crh']\n",
    "tracks=['2']\n",
    "data_classes = ['test', 'dev']\n",
    "\n",
    "train_steps=1000\n",
    "valid_steps=100\n",
    "save_checkpoint_steps = valid_steps\n",
    "\n",
    "train_params = [\n",
    "    f\"-train_steps {train_steps}\",\n",
    "    f\"-valid_steps {valid_steps}\",\n",
    "    f\"-save_checkpoint_steps {save_checkpoint_steps}\",\n",
    "    f\"-world_size 1\",\n",
    "    f\"-gpu_ranks 0 1\",\n",
    "    f\"-encoder_type brnn\"\n",
    "]\n",
    "\n",
    "pred_params = [\n",
    "    f\"-replace_unk\",\n",
    "    f\"-verbose\",\n",
    "    f\"-n_best 8\",\n",
    "    f\"-beam 8\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### data modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataModifyer:\n",
    "    @staticmethod\n",
    "    def modify_src_line(line):\n",
    "        return line\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def restore_src_line(line):\n",
    "        return line\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_tgt_line(line):\n",
    "        return line.split('+')[0].rstrip(' ')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def restore_tgt_line(line):\n",
    "        return line\n",
    "\n",
    "\n",
    "class NBestDataModifyer:\n",
    "    @staticmethod\n",
    "    def sent_to_baseline_compatible(line):\n",
    "        return line\n",
    "\n",
    "    @staticmethod\n",
    "    def hyp_to_baseline_compatible(line):\n",
    "        line_splitted = line.split('] [')\n",
    "        line_splitted[1] = (line_splitted[1].split(']')[0])\n",
    "        if len(line_splitted) < 2 or line_splitted[1] == \"\":\n",
    "            line_splitted[1] = '\\'?\\''\n",
    "        return line_splitted[0] + '] [' + ', '.join([line_splitted[1], '\\'+NOUN\\'', '\\'+Tag1=Value1\\'', '\\'+Tag2=Value2\\'', '\\'+Language=lan\\'']) + ']'\n",
    "\n",
    "\n",
    "class DataEvaluator:\n",
    "    otypes = [\"lemma\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def update_data(data, line):\n",
    "        lan, wf, lemma, pos, msd = line.split('\\t')\n",
    "\n",
    "        data[\"lemma\"][wf].add(lemma)\n",
    "\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(langs, tracks, train_params, prediction_params, dataModifyer, nbestModifyer, dataEvaluator):\n",
    "    mlUtil = MLUtil(prediction_params, dataModifyer, nbestModifyer)\n",
    "    for lang in langs:\n",
    "        for track in tracks:\n",
    "\n",
    "            # filenames, many of them\n",
    "            train_covered_filename = f\"train/{lang}-track{track}-covered\"\n",
    "            train_uncovered_filename = f\"train/{lang}-track{track}-uncovered\"\n",
    "            train_res_src_filename = f\"onmt-data/{lang}-track{track}-src-train.txt\"\n",
    "            train_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-train.txt\"\n",
    "\n",
    "            test_covered_filename = f\"test/{lang}-covered\"\n",
    "            test_uncovered_filename = f\"test/{lang}-uncovered\"\n",
    "            test_res_src_filename = f\"onmt-data/{lang}-track{track}-src-test.txt\"\n",
    "            test_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-test.txt\"\n",
    "            test_pred_output_filename = f\"results/{lang}-track{track}-test-covered.sys\" # output :)\n",
    "\n",
    "            val_covered_filename = f\"dev/{lang}-covered\"\n",
    "            val_uncovered_filename = f\"dev/{lang}-uncovered\"\n",
    "            val_res_src_filename = f\"onmt-data/{lang}-track{track}-src-dev.txt\"\n",
    "            val_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-dev.txt\"\n",
    "            val_pred_output_filename = f\"results/{lang}-track{track}-dev-covered.sys\" # output :)\n",
    "\n",
    "\n",
    "            model_filename = f\"models/{lang}-track{track}.model\"\n",
    "\n",
    "            score_log_filename = f\"{lang}-{track}-score.log\"\n",
    "            get_ipython().system(f'touch {score_log_filename}')\n",
    "\n",
    "\n",
    "            # ml| data preprocessing\n",
    "            mlUtil.generate_data(train_uncovered_filename, train_res_src_filename, train_res_tgt_filename)\n",
    "            mlUtil.generate_data(val_uncovered_filename, val_res_src_filename, val_res_tgt_filename)\n",
    "            mlUtil.generate_data(test_covered_filename, test_res_src_filename, test_res_tgt_filename)\n",
    "\n",
    "            # ml| training\n",
    "            mlUtil.train(train_res_src_filename, train_res_tgt_filename, val_res_src_filename, val_res_tgt_filename, model_filename, train_params)\n",
    "\n",
    "            # ml| predict and eval for test\n",
    "            mlUtil.predict(model_filename, test_res_src_filename, test_covered_filename, test_pred_output_filename)\n",
    "            get_ipython().system(f'echo \"*===QUALITY ON TEST DATA===*\" >> {score_log_filename}')\n",
    "            mlUtil.score_predictions(test_pred_output_filename, test_uncovered_filename, score_log_filename, dataEvaluator)\n",
    "\n",
    "\n",
    "            # ml| predict and eval for val\n",
    "            mlUtil.predict(model_filename, val_res_src_filename, val_covered_filename, val_pred_output_filename)\n",
    "\n",
    "\n",
    "            get_ipython().system(f'echo \"*===QUALITY ON VAL DATA===*\" >> {score_log_filename}')\n",
    "            mlUtil.score_predictions(val_pred_output_filename, val_uncovered_filename, score_log_filename, dataEvaluator)\n",
    "\n",
    "            # log eval results\n",
    "            get_ipython().system(f'cat {score_log_filename}')\n",
    "\n",
    "            # send eval to @oserikov at telegram\n",
    "            if telegram_notifications_enabled:\n",
    "                telegram_message = f\"#score\\n{lang}\\n{track}\\n\"+''.join(open(score_log_filename).readlines())+'\\n'+EXP_DESCRIPTION\n",
    "\n",
    "                telegram_message_encoded = urllib.parse.quote(telegram_message)\n",
    "                get_ipython().system(f'curl -i -X GET \"https://api.telegram.org/bot{bot_token}/sendMessage?chat_id={chat_id}&text={telegram_message_encoded}&parse_mode=markdown\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml(langs, tracks, train_params, pred_params, TrainDataModifyer, NBestDataModifyer, DataEvaluator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
