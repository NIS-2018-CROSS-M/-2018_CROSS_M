{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### set up telegram notifications\n",
    "\n",
    "  не очень понятно, нужно ли это.\n",
    "\n",
    "  если нужно -- напишите @oserikov в телеграме, я расскажу, что сделать,\n",
    "  чтобы присылались сообщения с качеством модели когда она отработает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_notifications_enabled=False\n",
    "EXP_DESCRIPTION = \"BASELINE\"\n",
    "\n",
    "if telegram_notifications_enabled:\n",
    "    bot_token = input(\"введите telegram bot token: \")\n",
    "    chat_id = \"292749902\" # for @oserikov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### install prereqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system(f\"git clone https://github.com/NIS-2018-CROSS-M/colab-tools.git\")\n",
    "get_ipython().magic(f\"cd colab-tools\")\n",
    "get_ipython().system(f\"bash colab-install-opennmt.sh\")\n",
    "get_ipython().system(f\"bash colab-install-cuda92-pytorch41.sh\")\n",
    "get_ipython().system(f\"bash colab-install-torchtext.sh\")\n",
    "get_ipython().magic(f\"cd ..\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies used in calma project\n",
    "get_ipython().system('/usr/bin/python3 -m pip install configargparse')\n",
    "get_ipython().system('git clone https://github.com/NIS-2018-CROSS-M/calma_tools.git')\n",
    "\n",
    "# receive the calma\n",
    "get_ipython().system('git clone https://github.com/ftyers/calma.git')\n",
    "get_ipython().magic('cd calma')\n",
    "get_ipython().system('git checkout -b latest-known-version d4ce3758d06538933855f734a44630efc8e2b6b2')\n",
    "get_ipython().system('rm sharedtaskdata/onmt-data/*')\n",
    "get_ipython().system('rm sharedtaskdata/results/*')\n",
    "get_ipython().magic('cd ..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as dd\n",
    "from random import shuffle\n",
    "import re\n",
    "import sys\n",
    "sys.path.append(get_ipython().getoutput(\"readlink -e calma_tools\")[0])\n",
    "from calma_tools.ml_util import MLUtil\n",
    "import urllib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic('cd calma/sharedtaskdata')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs=['crh']\n",
    "tracks=['2']\n",
    "data_classes = ['test', 'dev']\n",
    "\n",
    "train_steps=1000\n",
    "valid_steps=100\n",
    "save_checkpoint_steps = valid_steps\n",
    "\n",
    "train_params = [\n",
    "    f\"-train_steps {train_steps}\",\n",
    "    f\"-valid_steps {valid_steps}\",\n",
    "    f\"-save_checkpoint_steps {save_checkpoint_steps}\",\n",
    "    f\"-world_size 1\",\n",
    "    f\"-gpu_ranks 0 1\",\n",
    "    f\"-encoder_type brnn\"\n",
    "]\n",
    "\n",
    "pred_params = [\n",
    "    f\"-replace_unk\",\n",
    "    f\"-verbose\",\n",
    "    f\"-n_best 8\",\n",
    "    f\"-beam 8\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### data modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataModifyer:\n",
    "    @staticmethod\n",
    "    def modify_src_line(line):\n",
    "        return line\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def restore_src_line(line):\n",
    "        return line\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_tgt_line(line):\n",
    "        return line\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def restore_tgt_line(line):\n",
    "        return line\n",
    "\n",
    "\n",
    "class NBestDataModifyer:\n",
    "    @staticmethod\n",
    "    def sent_to_baseline_compatible(line):\n",
    "        return line\n",
    "                       \n",
    "    @staticmethod\n",
    "    def hyp_to_baseline_compatible(line):\n",
    "        return line\n",
    "\n",
    "    \n",
    "class DataEvaluator:\n",
    "    otypes = [\"analysis\",\"lemma\",\"tag\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def update_data(data, line):\n",
    "        lan, wf, lemma, pos, msd = line.split('\\t')\n",
    "        \n",
    "        data[\"analysis\"][wf].add((lemma,pos,msd))\n",
    "        data[\"lemma\"][wf].add(lemma)\n",
    "        data[\"tag\"][wf].add((pos,msd))\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CognatesTool:\n",
    "    words_info = {}\n",
    "\n",
    "    def __init__(self, ud_data_filenames):\n",
    "        for fn in ud_data_filenames:\n",
    "            with open(fn, 'r', encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    lang, wf, lemma, pos, morph_a = line.rstrip().split('\\t')\n",
    "                    if wf not in self.words_info.keys():\n",
    "                        self.words_info[wf] = []\n",
    "                    \n",
    "                    self.words_info[wf].append(\n",
    "                        {\n",
    "                            \"lang\": lang,\n",
    "                            \"wf\": wf,\n",
    "                            \"lemma\": lemma,\n",
    "                            \"pos\": pos,\n",
    "                            \"morph_a\": morph_a\n",
    "                        }\n",
    "                    )\n",
    "        print(str(len(self.words_info.keys())) + \" words have cognates\")\n",
    "\n",
    "    def get_words(self):\n",
    "        return self.words_info.keys()\n",
    "\n",
    "    def word_has_cognates(self, word):\n",
    "        return word in self.get_words()\n",
    "\n",
    "    def has_cognates(self, line, onmt_style=False):\n",
    "        if onmt_style:\n",
    "            res = self.word_has_cognates(''.join(line.rstrip().split()))\n",
    "        else:\n",
    "            # ud style lang \\t wordform \\t lemma \\t pos \\t analyses \\t i want to sleeeeep\n",
    "            res = self.word_has_cognates(line.rstrip().split('\\t')[1])\n",
    "        return res\n",
    "\n",
    "    def predict(self, src_filename, output_filename):\n",
    "        with open(src_filename, 'r', encoding=\"utf-8\") as f_src,             open(output_filename, 'w', encoding=\"utf-8\") as f_tgt:\n",
    "            \n",
    "            for line in f_src:\n",
    "                lang, wf, lemma, pos, morph_a = line.rstrip().split('\\t')\n",
    "                \n",
    "                if wf not in self.get_words():\n",
    "                    continue                \n",
    "                \n",
    "                for analysis_set in self.words_info[wf]:\n",
    "                    print('\\t'.join([analysis_set[\"lang\"],\n",
    "                                     analysis_set[\"wf\"],\n",
    "                                     analysis_set[\"lemma\"],\n",
    "                                     analysis_set[\"pos\"],\n",
    "                                     analysis_set[\"morph_a\"]]),\n",
    "                          file=f_tgt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(langs, tracks, train_params, prediction_params, dataModifyer, nbestModifyer, dataEvaluator):\n",
    "    mlUtil = MLUtil(prediction_params, dataModifyer, nbestModifyer)\n",
    "    for lang in langs:\n",
    "        for track in tracks:\n",
    "\n",
    "            # filenames, many of them\n",
    "            train_covered_filename = f\"train/{lang}-track{track}-covered\"\n",
    "            train_uncovered_filename = f\"train/{lang}-track{track}-uncovered\"\n",
    "            train_res_src_filename = f\"onmt-data/{lang}-track{track}-src-train.txt\"\n",
    "            train_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-train.txt\"\n",
    "\n",
    "            test_covered_filename = f\"test/{lang}-covered\"\n",
    "            test_uncovered_filename = f\"test/{lang}-uncovered\"\n",
    "            test_res_src_filename = f\"onmt-data/{lang}-track{track}-src-test.txt\"\n",
    "            test_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-test.txt\"\n",
    "            test_pred_output_filename = f\"results/{lang}-track{track}-test-covered.sys\" # output :)\n",
    "\n",
    "            val_covered_filename = f\"dev/{lang}-covered\"\n",
    "            val_uncovered_filename = f\"dev/{lang}-uncovered\"\n",
    "            val_res_src_filename = f\"onmt-data/{lang}-track{track}-src-dev.txt\"\n",
    "            val_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-dev.txt\"\n",
    "            val_pred_output_filename = f\"results/{lang}-track{track}-dev-covered.sys\" # output :)\n",
    "\n",
    "\n",
    "            model_filename = f\"models/{lang}-track{track}.model\"\n",
    "\n",
    "            score_log_filename = f\"{lang}-{track}-score.log\"\n",
    "            get_ipython().system(f'touch {score_log_filename}')\n",
    "\n",
    "\n",
    "            # ml| data preprocessing\n",
    "            mlUtil.generate_data(train_uncovered_filename, train_res_src_filename, train_res_tgt_filename)\n",
    "            mlUtil.generate_data(val_uncovered_filename, val_res_src_filename, val_res_tgt_filename)\n",
    "            mlUtil.generate_data(test_covered_filename, test_res_src_filename, test_res_tgt_filename)\n",
    "\n",
    "            # ml| training\n",
    "            mlUtil.train(train_res_src_filename, train_res_tgt_filename, val_res_src_filename, val_res_tgt_filename, model_filename, train_params)\n",
    "\n",
    "            # ml| predict and eval for test\n",
    "            mlUtil.predict(model_filename, test_res_src_filename, test_covered_filename, test_pred_output_filename)\n",
    "            get_ipython().system(f'echo \"*===QUALITY ON TEST DATA===*\" >> {score_log_filename}')\n",
    "            mlUtil.score_predictions(test_pred_output_filename, test_uncovered_filename, score_log_filename, dataEvaluator)\n",
    "\n",
    "\n",
    "            # ml| predict and eval for val\n",
    "            \n",
    "            # cognates heuristic: use ml for val data non having cognates, copy analysis of cognates\n",
    "            cognates_tool = CognatesTool([train_uncovered_filename])\n",
    "            # split the val data onto cognates-having(below) and cognates non-having\n",
    "            val_res_src_for_ml_filename = val_res_src_filename+\"for_ml\"\n",
    "            val_res_src_for_cognates_filename = val_res_src_filename+\"for_cognates\"\n",
    "            with open(val_res_src_filename, 'r', encoding=\"utf-8\") as f,                 open(val_res_src_for_ml_filename, 'w', encoding=\"utf-8\") as f_ml,                 open(val_res_src_for_cognates_filename, 'w', encoding=\"utf-8\") as f_cog:\n",
    "                for line in f:\n",
    "                    print(line.rstrip(), file=f_cog if cognates_tool.has_cognates(line, onmt_style=True) else f_ml)\n",
    "            # split the val data onto cognates-having and cognates non-having (below)\n",
    "            val_covered_for_ml_filename = val_covered_filename+\"for_ml\"\n",
    "            val_covered_for_cognates_filename = val_covered_filename+\"for_cognates\"\n",
    "            with open(val_covered_filename, 'r', encoding=\"utf-8\") as f,                 open(val_covered_for_ml_filename, 'w', encoding=\"utf-8\") as f_ml,                 open(val_covered_for_cognates_filename, 'w', encoding=\"utf-8\") as f_cog:\n",
    "                for line in f:\n",
    "                    print(line.rstrip(), file=f_cog if cognates_tool.has_cognates(line) else f_ml)\n",
    "\n",
    "            # predict analysis for cognates non-having, copy analysis from cognates for cognates-having\n",
    "            val_pred_for_ml_output_filename = val_pred_output_filename+\"for_ml\"\n",
    "            val_pred_for_cognates_output_filename = val_pred_output_filename+\"for_cognates\"\n",
    "            \n",
    "            mlUtil.predict(model_filename, val_res_src_for_ml_filename, val_covered_for_ml_filename, val_pred_for_ml_output_filename)\n",
    "            cognates_tool.predict(val_covered_for_cognates_filename, val_pred_for_cognates_output_filename)\n",
    "            \n",
    "            # merge prediction of both approaches\n",
    "            get_ipython().system(f'cat {val_pred_for_ml_output_filename} >> {val_pred_output_filename} '                                  + '&& '                                  + f'cat {val_pred_for_cognates_output_filename} >> {val_pred_output_filename}')\n",
    "            \n",
    "            get_ipython().system(f'echo \"*===QUALITY ON VAL DATA===*\" >> {score_log_filename}')\n",
    "            mlUtil.score_predictions(val_pred_output_filename, val_uncovered_filename, score_log_filename, dataEvaluator)\n",
    "\n",
    "            # log eval results\n",
    "            get_ipython().system(f'cat {score_log_filename}')\n",
    "\n",
    "            # send eval to @oserikov at telegram\n",
    "            if telegram_notifications_enabled:\n",
    "                telegram_message = f\"#score\\n{lang}\\n{track}\\n\"+''.join(open(score_log_filename).readlines())+'\\n'+EXP_DESCRIPTION\n",
    "\n",
    "                telegram_message_encoded = urllib.parse.quote(telegram_message)\n",
    "                get_ipython().system(f'curl -i -X GET \"https://api.telegram.org/bot{bot_token}/sendMessage?chat_id={chat_id}&text={telegram_message_encoded}&parse_mode=markdown\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml(langs, tracks, train_params, pred_params, TrainDataModifyer, NBestDataModifyer, DataEvaluator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2.0,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3.0
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
