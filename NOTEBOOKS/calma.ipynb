{"cells":[{"cell_type":"markdown","source":[" ## set up telegram notifications\n","\n"," не очень понятно, нужно ли это. если нужно -- напишите @oserikov в телеграме, я расскажу, что сделать, чтобы присылались сообщения с качеством модели когда она отработает."],"metadata":{}},{"source":["telegram_notifications_enabled=False\n","EXP_DESCRIPTION = \"PREDICT ONLY MORPHOLOGICAL ANALYSIS\"\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["if telegram_notifications_enabled:\n","    bot_token = input(\"введите telegram bot token: \")\n","    chat_id = \"292749902\" # for @oserikov\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # prepare"],"metadata":{}},{"source":["import sys\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" #### install prereqs"],"metadata":{}},{"source":["\n","# clone openmt-py used in calma and move it into the proper folder\n","get_ipython().system('git clone https://github.com/OpenNMT/OpenNMT-py.git')\n","get_ipython().magic('cd OpenNMT-py')\n","get_ipython().system('git checkout -b stable-version d57fa68e6b0c2041642af40f76e1d5903c80a9b8')\n","get_ipython().magic('cd ..')\n","get_ipython().system('mv OpenNMT-py ~')\n","get_ipython().system('wget -q https://raw.githubusercontent.com/NIS-2018-CROSS-M/calma/tmp-utils/utils/onmt-decoder.py -O ~/OpenNMT-py/onmt/decoders/decoder.py')\n","get_ipython().system('wget -q https://raw.githubusercontent.com/NIS-2018-CROSS-M/calma/tmp-utils/utils/onmt-opts.py -O ~/OpenNMT-py/onmt/opts.py')\n","\n","# clone and run a tool installing pytorch 0.4.1 with cuda 9.2 into colab (maybe works on any ubuntu 16)\n","get_ipython().system('git clone https://gist.github.com/f7b7c7758a46da49f84bc68b47997d69.git colab_cuda_upgrader')\n","get_ipython().system('bash colab_cuda_upgrader/pytorch041_cuda92_colab.sh')\n","\n","# install dependencies used in calma project\n","get_ipython().system('{sys.executable} -m pip install configargparse')\n","\n","# install the proper version of torchtext\n","get_ipython().system('git clone https://github.com/pytorch/text.git')\n","get_ipython().magic('cd text')\n","get_ipython().system('{sys.executable} -m pip install .')\n","get_ipython().magic('cd ..')\n","\n","# receive the calma\n","get_ipython().system('git clone https://github.com/ftyers/calma.git')\n","get_ipython().magic('cd calma')\n","get_ipython().system('git checkout -b latest-known-version d4ce3758d06538933855f734a44630efc8e2b6b2')\n","get_ipython().magic('cd sharedtaskdata')\n","get_ipython().system('rm onmt-data/*')\n","get_ipython().system('rm results/*')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" #### imports"],"metadata":{}},{"source":["from collections import defaultdict as dd\n","from random import shuffle\n","import re\n","import urllib\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## helping functions definitions"],"metadata":{}},{"source":["def score_predictions(res_file_fn, gold_file_fn, output_fn, dataEvaluator):   \n","    \n","    def readdata(fn):\n","        data = {otype:dd(set) for otype in dataEvaluator.otypes}\n","        for line in open(fn):\n","            line = line.strip('\\n')\n","            if line:\n","                data = dataEvaluator.update_data(data, line)\n","        return data\n","    \n","    sysdata = readdata(res_file_fn)\n","    golddata = readdata(gold_file_fn)\n","    \n","    output_f = open(output_fn, 'a+', encoding='utf-8')\n","    for otype in dataEvaluator.otypes:\n","        tp = 0\n","        fp = 0\n","        fn = 0\n","        for wf in sysdata[otype]:\n","            tp += len(sysdata[otype][wf] & golddata[otype][wf])\n","            fp += len(sysdata[otype][wf] - golddata[otype][wf])\n","            fn += len(golddata[otype][wf] - sysdata[otype][wf])\n","        recall = tp/(tp+fn)\n","        precision = tp/(tp+fp)\n","        fscore = 2 * recall * precision / (recall + precision)\n","        print(\"Recall for %s: %.2f\" % (otype,recall*100), file = output_f)\n","        print(\"Precision for %s: %.2f\" % (otype,precision*100), file = output_f)\n","        print(\"F1-score for %s: %.2f\" % (otype,fscore*100), file = output_f)\n","        print(\"\", file = output_f)\n","    \n","    output_f.close()\n","\n","def modify_nbest(nbest_src_filename, nbest_tgt_filename, nbestModifyer):\n","    with open(nbest_src_filename, 'r', encoding='utf-8') as src_f,         open(nbest_tgt_filename, 'w', encoding='utf-8') as tgt_f:\n","\n","        for line in src_f.readlines():\n","            line = line.rstrip('\\n').rstrip('\\r')\n","            if line.startswith(\"SENT \"):\n","                line = nbestModifyer.sent_to_baseline_compatible(line)\n","            elif re.match(\"^\\[[\\-\\+]?\\d+\\.\\d+\\]\\s\\[\", line):\n","                line = nbestModifyer.hyp_to_baseline_compatible(line)\n","\n","            print(line, file=tgt_f)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["def initialize_data(train_src, train_tgt, valid_src, valid_tgt, prepared_training_data_prefix):\n","    prepr_params = f\"-train_src {train_src} -train_tgt {train_tgt} -valid_src {valid_src} -valid_tgt {valid_tgt} -save_data {prepared_training_data_prefix}\" \n","    get_ipython().system('{sys.executable} ~/OpenNMT-py/preprocess.py {prepr_params}')\n","\n","\n","def train_ml(train_params):\n","    train_params = \" \".join(train_params)\n","    get_ipython().system('{sys.executable} ~/OpenNMT-py/train.py {train_params}')\n","\n","\n","def generate_predictions(generation_params, output_filename):\n","    generation_params = \" \".join(generation_params)\n","    get_ipython().system('{sys.executable} ~/OpenNMT-py/translate.py {generation_params} > {output_filename}')\n","\n","\n","def choose_best_predictions(nbest_filename, covered_filename, output_filename):\n","    get_ipython().system('cat {nbest_filename} | grep -v -P \"^\\\\s+\" | grep -v -P \"^\\\\+\" | {sys.executable} scripts/get-analyses.py 0.8 3 {covered_filename} > {output_filename}')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" #### def data_generation"],"metadata":{}},{"source":["# the method called for each non-processed training data row\n","def get_data_entry(language, wordform, lemma, pos_tag, morphological_analysis):\n","    lemma = ' '.join(lemma)\n","    wordform = ' '.join(wordform)\n","    morphological_analysis = morphological_analysis.split('|')\n","    return wordform, '%s %s' % (lemma, ' '.join(['+%s' % x for x in [pos_tag] + morphological_analysis  + [\"Language=%s\" % language]]))\n","\n","\n","def generate_onmt_data(fn, res_src_fn, res_tgt_fn, DataModifyerClass):\n","    \n","    modify_src_line = DataModifyerClass.modify_src_line\n","    modify_tgt_line = DataModifyerClass.modify_tgt_line\n","    restore_orig_src_line = DataModifyerClass.restore_src_line\n","    restore_orig_tgt_line = DataModifyerClass.restore_tgt_line\n","    \n","    analyses = dd(set)\n","\n","    for line in open(fn, encoding='utf-8'):\n","        line = line.rstrip('\\n').rstrip('\\r')\n","        lang, wf, lemma, pos, msd = line.split('\\t')\n","        wf, a = get_data_entry(lang, wf, lemma, pos, msd)\n","        analyses[wf].add(a)\n","    \n","    tmp_src_fn = res_src_fn + \"-default\"\n","    tmp_tgt_fn = res_tgt_fn + \"-default\"\n","    \n","    tmp_src = open(tmp_src_fn, 'w')\n","    tmp_tgt = open(tmp_tgt_fn, 'w')\n","    res_src = open(res_src_fn, 'w')\n","    res_tgt = open(res_tgt_fn, 'w')\n","    \n","    analyses = list(analyses.items())\n","    shuffle(analyses)\n","\n","    for wf, analysis in analyses:\n","        for a in analysis:\n","            print(wf, file = tmp_src)\n","            print(a, file = tmp_tgt)\n","            print(modify_src_line(wf), file = res_src)\n","            print(modify_tgt_line(a), file = res_tgt)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### def ml()"],"metadata":{}},{"source":["def ml(langs, tracks, train_params, prediction_params, dataModifyer, nbestModifyer, dataEvaluator):\n","    \n","    def generate_data(orig_data_fn, res_src_fn, res_tgt_fn):\n","        return generate_onmt_data(orig_data_fn, res_src_fn, res_tgt_fn, dataModifyer)\n","\n","    def train(train_res_src_fn, train_res_tgt_fn, val_res_src_fn, val_res_tgt_fn, save_model_fn, train_params):\n","        data_fn = save_model_fn + \"-prepared_training_data\" #f\"onmt-data/{lang}-track{track}\"    \n","        initialize_data(train_res_src_fn, train_res_tgt_fn, val_res_src_fn, val_res_tgt_fn, data_fn)\n","\n","        train_params.extend([f\"-data {data_fn}\", f\"-save_model {save_model_fn}\"])\n","        train_ml(train_params)\n","        get_ipython().system('mv {save_model_fn}_step_{train_steps}.pt {save_model_fn}')\n","\n","    \n","    def predict(model_filename, input_data_filename, covered_filename, chosen_output_filename):\n","        output_data_filename = f\"{input_data_filename}.out\"\n","        nbest_output_filename = f\"{input_data_filename}.nbest.out\"\n","        prediction_params.extend([\n","            f\"-model {model_filename}\",\n","            f\"-src {input_data_filename}\",\n","            f\"-output {output_data_filename}\"\n","        ])\n","        generate_predictions(prediction_params, nbest_output_filename)\n","        nbest_output_modified_filename = nbest_output_filename+\"-modified\"\n","        modify_nbest(nbest_output_filename, nbest_output_modified_filename, nbestModifyer)\n","        choose_best_predictions(nbest_output_modified_filename, covered_filename, chosen_output_filename)\n","\n","    \n","    for lang in langs:\n","        for track in tracks:\n","            train_covered_filename = f\"train/{lang}-track{track}-covered\"\n","            train_uncovered_filename = f\"train/{lang}-track{track}-uncovered\"\n","            val_covered_filename = f\"dev/{lang}-covered\"\n","            val_uncovered_filename = f\"dev/{lang}-uncovered\"\n","            test_covered_filename = f\"test/{lang}-covered\"\n","            test_uncovered_filename = f\"test/{lang}-uncovered\"\n","\n","            train_res_src_filename = f\"onmt-data/{lang}-track{track}-src-train.txt\"\n","            train_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-train.txt\"\n","\n","            val_res_src_filename = f\"onmt-data/{lang}-track{track}-src-dev.txt\"\n","            val_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-dev.txt\"\n","\n","            test_res_src_filename = f\"onmt-data/{lang}-track{track}-src-test.txt\"\n","            test_res_tgt_filename = f\"onmt-data/{lang}-track{track}-tgt-test.txt\"\n","\n","\n","            generate_data(train_uncovered_filename, train_res_src_filename, train_res_tgt_filename)        \n","            generate_data(val_uncovered_filename, val_res_src_filename, val_res_tgt_filename)\n","\n","            model_filename = f\"models/{lang}-track{track}.model\"\n","            train(train_res_src_filename, train_res_tgt_filename, val_res_src_filename, val_res_tgt_filename, model_filename, train_params)\n","\n","\n","            score_log_filename = f\"{lang}-{track}-score.log\"\n","            get_ipython().system('echo \"\" > {score_log_filename}')\n","\n","            generate_data(test_covered_filename, test_res_src_filename, test_res_tgt_filename)\n","            test_pred_output_filename = f\"results/{lang}-track{track}-test-covered.sys\"\n","            predict(model_filename, test_res_src_filename, test_covered_filename, test_pred_output_filename)\n","            get_ipython().system('echo \"*===QUALITY ON TEST DATA===*\" >> {score_log_filename}')\n","            score_predictions(test_pred_output_filename, test_uncovered_filename, score_log_filename, dataEvaluator)\n","\n","            val_pred_output_filename = f\"results/{lang}-track{track}-dev-covered.sys\"\n","            predict(model_filename, val_res_src_filename, val_covered_filename, val_pred_output_filename)\n","            get_ipython().system('echo \"*===QUALITY ON VAL DATA===*\" >> {score_log_filename}')\n","            score_predictions(val_pred_output_filename, val_uncovered_filename, score_log_filename, dataEvaluator)\n","\n","            get_ipython().system('cat {score_log_filename}')\n","            \n","            if telegram_notifications_enabled:\n","                telegram_message = \"#score\\n\"+''.join(open(score_log_filename).readlines())+'\\n'+EXP_DESCRIPTION\n","\n","                telegram_message_encoded = urllib.parse.quote(telegram_message)\n","                get_ipython().system('curl -i -X GET \"https://api.telegram.org/bot{bot_token}/sendMessage?chat_id={chat_id}&text={telegram_message_encoded}&parse_mode=markdown\"')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # ML"],"metadata":{}},{"cell_type":"markdown","source":[" ## set ml params"],"metadata":{}},{"source":["langs=['ast']\n","tracks=['1']\n","data_classes = ['test', 'dev']\n","\n","train_steps=1000\n","valid_steps=100\n","save_checkpoint_steps = valid_steps\n","\n","train_params = [\n","    f\"-train_steps {train_steps}\",\n","    f\"-valid_steps {valid_steps}\",\n","    f\"-save_checkpoint_steps {save_checkpoint_steps}\",\n","    f\"-world_size 1\",\n","    f\"-gpu_ranks 0 1\",\n","    f\"-encoder_type brnn\"\n","]\n","\n","pred_params = [\n","    f\"-replace_unk\",\n","    f\"-verbose\",\n","    f\"-n_best 8\",\n","    f\"-beam 8\"\n","]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Predict only morphological analysis approach"],"metadata":{}},{"cell_type":"markdown","source":[" #### data description"],"metadata":{}},{"cell_type":"markdown","source":[" **source**\n"," ```\n"," wf1 wf2 ... wfN\n"," ```\n","\n"," **target**\n"," ```\n"," +Tag1=Value1 ... +TagN=ValueN\n"," ```\n","\n"," **uncovered**\n"," (tab separated)\n"," ```\n"," langCode\twordForm\tlemma\tPOS\tTag1=Value1|...|TagN=ValueN\n"," ```\n","\n"," **prediction** raw\n"," ```\n"," SENT 1: ['wf1', 'wf2', ..., 'wfN']\n"," ...\n"," [-9.2825] ['+Tag1=Value1', ..., '+TagN=ValueN']\n"," ```\n"," **prediction** passed to `eval()`\n"," ```\n"," ['c', 'c', '+NOUN', '+Tag1=Value1', ..., '+TagN=ValueN', '+Language=lan']\n"," ```\n","\n"," prediction then is converted to follow the uncovered file pattern\n"," ```\n"," langCode\twordForm\tlemma\tPOS\tTag1=Value1|...|TagN=ValueN\n"," ```\n","\n",""],"metadata":{}},{"cell_type":"markdown","source":[" #### embeddings\n"," * character-level input embeddings\n"," * character-level output embeddings\n"," * learned\n"," * initialized with random"],"metadata":{}},{"cell_type":"markdown","source":[" #### data modification"],"metadata":{}},{"source":["class TrainDataModifyer:\n","    def modify_src_line(line):\n","        return line\n","\n","\n","    def restore_src_line(line):\n","        return line\n","\n","\n","    def modify_tgt_line(line):\n","        return ' '.join(['+'+tag for tag in line.split('+') if '=' in tag and not tag.startswith(\"Language=\")]).rstrip(' ')\n","\n","\n","    def restore_tgt_line(line):\n","        return line\n","\n","\n","class NBestDataModifyer:\n","    def sent_to_baseline_compatible(line):\n","        return line\n","                       \n","    def hyp_to_baseline_compatible(line):\n","        line_splitted = line.split('] [')\n","        line_splitted[1] = (line_splitted[1].split(']')[0])\n","        if len(line_splitted) < 2 or line_splitted[1] == \"\":\n","            line_splitted[1] = '\\'+Tag0=?\\''\n","        return line_splitted[0] + '] [' + ', '.join(['\\'c\\'','\\'c\\'', '\\'+NOUN\\'', line_splitted[1], '\\'+Language=lan\\'']) + ']'\n","\n","    \n","class DataEvaluator:\n","    otypes =  [\"morph analysis\"]\n","    \n","    def update_data(data, line):\n","        lan, wf, lemma, pos, msd = line.split('\\t')\n","        \n","        data[\"morph analysis\"][wf].add(msd)\n","        \n","        return data\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" #### ml"],"metadata":{}},{"source":["ml(langs, tracks, train_params, pred_params, TrainDataModifyer, NBestDataModifyer, DataEvaluator)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # sandbox"],"metadata":{}},{"source":["\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}